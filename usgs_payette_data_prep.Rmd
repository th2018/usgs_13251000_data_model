---
title: "USGS 13251000 PAYETTE "
output: html_document
---

# Step 1: load the packages
# Step 2: Read PRISM data
# Step 3: Load USGS data
# Step 4: Merge PRISM and USGS

# Step 1: load the packages
```{r include=FALSE}
# install.packages("dataRetrieval")
#library(dataRetrieval) # for getting USGS NWIS data
# install.packages("tidyhydat")
library(tidyhydat) # for getting ECCC HYDAT data
# download_hydat()
library(dplyr) # for data wrangling and pipelines
library(ggplot2) # for modifying fasstr plots
library("dplyr")
#install.packages('corrplot')
library(corrplot)
library(RColorBrewer)
# install.packages("gbm")
library("gbm")
# install.packages("caret")
library("caret")
#install.packages("pdp")
library("pdp")          # model visualization
library("ggplot2")      # model visualization
#install.packages("lime")
library("lime")         # model visualization
library("pROC")
#install.packages("e1071", repos="http://R-Forge.R-project.org")
library("e1071")
library( "MASS" )    #    used to generate correlated variables
library("sp")
library("Hmisc")    #   used for graphing se bars
#install.packages("randomForest")
require("randomForest")
#install.packages("e1071")
library(e1071)
library(caret)
library("ModelMetrics")
library("foreign")
#install.packages("rfUtilities")
library("rfUtilities")
library("lubridate")
#  install.packages("feasts")
library(feasts)
library(tsibble)
#  install.packages("TSstudio")
#library(TSstudio)
#library(plotly)
# third approach
library(tidyverse)
# install.packages("timetk")
#library("timetk")
```

# Step 2: Read PRISM data
```{r}
#met<-read.csv("3211707.csv")
#table(unique(met$STATION))
#met$DATE<-as.Date(met$DATE, format="%Y-%m-%d")

prism<-read.csv("PRISM_ppt_tmin_tmean_tmax_tdmean.csv")
prism$Date <-as.Date(prism$Date, format="%Y-%m-%d")
summary(prism)

#prism_met<-merge(prism,met,by.x="Date",by.y="DATE")
#prism_met$mo<-month(prism_met$Date)
#prism_met$diff_max<-prism_met$tmax..degrees.C.-prism_met$TMAX
#summary(prism_met[prism_met$mo %in% c(6,7,8),])
#plot(prism_met[prism_met$mo %in% c(6,7,8),]$tmax..degrees.C. , prism_met[prism_met$mo %in% c(6,7,8),]$TMAX)
#hist(prism_met[prism_met$mo %in% c(6,7,8),]$tmax..degrees.C.)
#hist(prism_met[prism_met$mo %in% c(6,7,8),]$TMAX)
#summary(prism_met[prism_met$mo %in% c(6,7,8),]$diff_max)
```

# Step 3: Load USGS data
```{r}
st_all_gage<-c("13251000")
#create empty tables
meanSummerT_df<-data.frame(
  agency_cd= " ",
  site_no="",
  Date=as.Date("1951-01-01",format="%Y-%m-%d"),
  X_00010_00001=0,
  X_00010_00001_cd=0,
  X_00010_00003=0,
  X_00010_00003_cd= "",
  X_00060_00003=0,    
  X_00060_00003_cd= "",
  yr="",
  mo=0
  )
for (id in st_all_gage) {
  siteNumber <-  id 
  parameterCd <- c("00010","00060") 
  #00060: Discharge, cubic feet per second
  #00010	Physical	Temperature, water, degrees Celsius	
  ChoptankInfo <- readNWISsite(siteNumber)
 #ChoptankInfo$alt_va : Gage datum feet above NGVD29
  #statCd <- c("00003") 
  #00001 max
  #00003 mean
  startDate <- "1997-10-01"
  endDate <- "2018-09-30"
  meanT <-readNWISdv(siteNumber, parameterCd,startDate, endDate, statCd= c("00001","00003"))
  if (dim(meanT )[2]>5){
    meanT$yr<- format(meanT$Date, format = "%Y") 
    meanT$mo<-as.numeric(format(meanT$Date, format = "%m"))
    meanSummerT<-meanT[ ,c("agency_cd","site_no","Date"
                           ,"X_00010_00001"
                           ,"X_00010_00001_cd"
                           ,"X_00010_00003","X_00010_00003_cd","X_00060_00003","X_00060_00003_cd","yr","mo"  )]
#    meanAugT<-meanT[meanT$mo==8,c("agency_cd","site_no","Date","X_00010_00001","X_00010_00001_cd","X_00010_00003","X_00010_00003_cd","X_00060_00003","X_00060_00003_cd","yr","mo"  )]
    
    meanSummerT_df <-rbind(meanSummerT_df,meanSummerT)
    print(    paste(id,dim(meanT )[1],Sys.time() ) )
  }
}
df<-meanSummerT_df[ !is.na(meanSummerT_df$X_00010_00003) &  !meanSummerT_df$mo<1 ,]
summary(df)
```

```{r}
df<-readRDS("USGS_13251000_ST_Q.rds")
summary(df)
```

```{r}
table(df[df$mo %in% c(6,7,8),]$yr)
```

# Step 4: Merge PRISM and USGS
```{r}
prism$Date <-as.Date(prism$Date, format="%Y-%m-%d")
prism_df<-merge(prism,df,by.x="Date",by.y= "Date")
prism_df$X_00010_00003 -> prism_df$mean_StreamTemp
prism_df$X_00010_00001-> prism_df$max_StreamTemp
log(prism_df$X_00060_00003)->prism_df$log_mean_Q
prism_df$tmax..degrees.C.->prism_df$max_AirTemperature_C
prism_df$tmean..degrees.C.->prism_df$mean_AirTemperature_C
prism_df$max_AirTemperature_C_1<-0
prism_df$mean_AirTemperature_C_1<-0
for (i in 2:dim(prism_df)[1]) {
prism_df[ i,]$max_AirTemperature_C_1<-prism_df[ i-1 ,]$max_AirTemperature_C
prism_df[ i,]$mean_AirTemperature_C_1<-prism_df[ i-1 ,]$mean_AirTemperature_C
}
prism_df$vpdmax..hPa.->prism_df$vpdmax
prism_df$doy<-yday( prism_df$Date )
prism_df$yr<-as.numeric(prism_df$yr)
prism_df<-prism_df[,c("Date", "yr", "vpdmax", "mean_AirTemperature_C","mean_AirTemperature_C_1", "max_AirTemperature_C", "max_AirTemperature_C_1","log_mean_Q", "max_StreamTemp", "mean_StreamTemp","mo","doy")]
summary(prism_df)
#saveRDS(prism_df,file = "13251000_prism_df.rds")
```

```{r}
prism_df<-readRDS("13251000_prism_df.rds")
table( prism_df[prism_df$mo %in% c(6,7,8),]$yr)
```

```{r}
prism_df<-prism_df[prism_df$yr %in% c(2016,2017,2018),]
#saveRDS( prism_df, file="13251000_prism_df.rds")
summary(prism_df)
table( prism_df[prism_df$mo %in% c(6,7,8),]$yr)
```






















# Step 5: specify year and month for analysis
# Step 6: Create the correlation plot
# Step 7: create training and test data









```{r}
prism_df <-readRDS("13251000_prism_df.rds")
prism_df2<-prism_df
prism_df2$yr<-as.character(prism_df$yr)
prism_df2$mo<-as.character(prism_df$mo)
max_ST_yr<-prism_df2 %>% group_by( yr ,  mo  )%>% summarise(max_ST = max(mean_StreamTemp),mean_ST=mean(mean_StreamTemp) )

max_ST_yr[max_ST_yr$mo %in% c("6",  "7" , "8"),]
boxplot(max_ST_yr[max_ST_yr$mo %in% c("6",  "7" , "8"),]$mean_ST~max_ST_yr[max_ST_yr$mo %in% c("6",  "7" , "8"),]$mo, ylab = "Monthly mean stream T (degC)", xlab="Month", main="USGS 13251000 PAYETTE RIVER NR PAYETTE ID")
```

# Step 5: specify year and month for analysis
```{r}
prism_df_2016_summer<-prism_df[prism_df$yr %in% c(2016,2017,2018) & prism_df$mo %in% c(7,8),]
#prism_df_2016_summer<-prism_df[prism_df$yr %in% c(2016,2017,2018) & prism_df$mo %in% c(7,8,9),]
summary(prism_df_2016_summer)
```


<!-- ```{r} -->
<!-- met$date<-as.Date(met$DATE, format="%Y-%m-%d")  -->
<!-- df$date<-as.Date( df$Date, format="%Y-%m-%d")  -->
<!-- met_df<-merge(met,df,by.x = "date" ,by.y = "date") -->
<!-- met_df$X_00010_00003-> met_df$mean_StreamTemp -->
<!-- log(met_df$X_00060_00003)->met_df$log_median_Q -->
<!-- met_df$TMAX ->met_df$max_AirTemperature_C -->
<!-- met_df$doy<-yday( met_df$date) -->

<!-- met_df<-met_df[,c("date","max_AirTemperature_C","mean_StreamTemp","log_median_Q","mo","yr","doy")] -->
<!-- daily_df_summer<-met_df[month(met_df$date) %in% c(6,7,8),] -->
<!-- ``` -->

<!-- ```{r} -->
<!-- daily_df_summer<-daily_df_summer[!is.na(daily_df_summer$max_AirTemperature_C),] -->
<!-- save(daily_df_summer,file="Payette_daily_df_summer.Rdata") -->
<!-- ``` -->

# Step 6: Create the correlation plot
```{r}
prism_df_2016_summer->daily_df_summer
M <-cor( daily_df_summer[,c("mean_StreamTemp","max_StreamTemp","log_mean_Q","mean_AirTemperature_C","mean_AirTemperature_C_1","max_AirTemperature_C_1","max_AirTemperature_C","vpdmax","doy")])
M
corrplot(M, type="upper", order="hclust",
         col=brewer.pal(n=8, name="RdYlBu"))
M_1 <-cor( daily_df_summer[,c("mean_StreamTemp" ,"log_mean_Q","mean_AirTemperature_C")])
corrplot(M_1, type="upper", order="hclust",
         col=brewer.pal(n=8, name="RdYlBu"))
```

# Step 7: create training and test data
```{r}
# set seed for generating random data.
set.seed(0)          
# createDataPartition() function from the caret package to split the original dataset into a training and testing set and split data into training (80%) and testing set (20%)
variables<-c("mean_StreamTemp","log_mean_Q"
             ,"mean_AirTemperature_C" 
           #  ,"vpdmax","doy"
         #  ,"air_Q"
             )
parts = createDataPartition(  daily_df_summer$mean_StreamTemp , p = .8, list = F)
train = daily_df_summer[parts, variables ]
test =  daily_df_summer[-parts, variables  ]
# feature and target array
test_x = test[, -1] 
test_y = test[, 1] 
```

<!-- # Model 1: lm -->
<!-- ```{r} -->
<!-- lm<-lm( mean_StreamTemp ~log_median_Q #+min_Discharge -->
<!--         +max_AirTemperature_C +doy , data =  train  ) -->
<!-- summary(lm) -->
<!-- RMSE = sqrt(mean(lm$residuals^2)) -->
<!-- cat('The root mean square error of the test data is ', round(RMSE,3),'\n') -->
<!-- predict<-predict(lm, test_x) -->
<!-- summary(test_y) -->
<!-- xmin=5 -->
<!-- xmax=30 -->
<!-- x=seq(xmin-5,xmax+5) -->
<!-- plot( test_y ,predict,xlim=c(xmin,xmax) ,ylim=c(xmin,xmax), xlab="Observed stream temperature (degC)", ylab="Predicted stream temperature (degC)") -->
<!-- par(new=T) -->
<!-- plot(x,x,type="l",xlim=c(xmin,xmax) ,ylim=c(xmin,xmax),xlab="",ylab="", main="LM") -->
<!-- ``` -->

# Step 8: run GBM
```{r}
model_gbm = gbm(train$mean_StreamTemp       ~.,
                data = train,
                distribution = "gaussian",
                cv.folds = 10,
                shrinkage = .01,
                n.minobsinnode = 10,
                n.trees = 800)
 
# model performance
perf_gbm1 = gbm.perf( model_gbm, method = "cv")
print(model_gbm)
summary(model_gbm)
rinf<-summary(model_gbm)
barplot( rinf$rel.inf , horiz = TRUE, las = 1)
ggplot(rinf, aes(rel.inf)) + geom_bar()
rinf$max_yr<-max(as.numeric(daily_df_summer$yr))
rinf$min_yr<-min(as.numeric(daily_df_summer$yr))
rinf$max_mo<-max(as.numeric(daily_df_summer$mo))
rinf$min_mo<-min(as.numeric(daily_df_summer$mo))
rinf$site_id<-13251000
saveRDS(rinf ,file=  paste("rinf", rinf$site_id[1], rinf$min_mo[1], rinf$max_mo[1],".rds",sep="_")    )
```

```{r}
rinf$var<- factor(rinf$var, levels=c(  "mean_AirTemperature_C" ,"log_mean_Q"
#, "doy" 
#,"air_Q"
))
ggplot( rinf, aes( var , rel.inf ))+  geom_col()+ 
  coord_flip()
ggplot( rinf )+  geom_bar(  aes( x=var, y= rel.inf),  stat = "summary")+ scale_x_discrete(labels=  c( "Mean Air Temperature (deg C)" ,"log(Mean Streamflow (cfs))"
 ) )+ylab("Relative importance (%)") +xlab(" ")  + theme(text=element_text(size=19))
```

```{r}
#test_y <-test_y$max_StreamTemp
pred_y = predict.gbm(model_gbm, test_x)
residuals =  test_y   - pred_y
summary(test_y )
xlim=c(15,30)
RMSE = sqrt(mean(residuals^2))
cat('The root mean square error of the test data is ', round(RMSE,3),'\n')
y_test_mean = mean( test_y  )
# Calculate total sum of squares
tss =  sum(( test_y   - y_test_mean)^2 )
# Calculate residual sum of squares
rss =  sum(residuals^2)
# Calculate R-squared
rsq  =  1 - (rss/tss)
cat('The R-square of the test data is ', round(rsq,3), '\n')
# visualize the model, actual and predicted data
x_ax = 1:length(pred_y)
plot(x_ax, test_y  , col="blue", pch=20, cex=.9)
lines(x_ax, pred_y, col="red", pch=20, cex=.9) 
plot(  test_y , pred_y,xlim= xlim ,ylim= xlim, xlab="Observed stream temperature (degC)", ylab="Predicted stream temperature (degC)", main="USGS 13251000 PAYETTE RIVER NR PAYETTE ID")
par(new=T)
x=seq(0,40)
plot(x,x,type="l",xlim= xlim ,ylim= xlim,xlab="",ylab="")
```

```{r}
model_gbm %>% partial(pred.var =  "mean_AirTemperature_C"   , n.trees = model_gbm$n.trees, grid.resolution = 100) %>% autoplot(rug = TRUE, train = train)+theme(axis.text=element_text(size=21),axis.title=element_text(size=24))

#,"min_Discharge"
model_gbm %>%
  partial(pred.var =  "log_median_Q"
             #,"min_Discharge"
               , n.trees = model_gbm$n.trees, grid.resolution = 100) %>%
  autoplot(rug = TRUE, train = train)+theme(axis.text=element_text(size=21),
        axis.title=element_text(size=24))

model_gbm %>%
  partial(pred.var =  "doy"
             #,"min_Discharge"
               , n.trees = model_gbm$n.trees, grid.resolution = 100) %>%
  autoplot(rug = TRUE, train = train)+theme(axis.text=element_text(size=21),
        axis.title=element_text(size=24))

```

```{r}
plot(daily_df_summer$doy,sinpi(daily_df_summer$doy/365 ))
     
plot(daily_df_summer$doy,cospi(daily_df_summer$doy/365))
plot(daily_df_summer$doy     ,daily_df_summer$mean_StreamTemp)
```

```{r}
# ts function is responsible to convert to ts object
daily_df_summer_2017<-daily_df_summer[daily_df_summer$yr==2018,]
ts <- ts(data = daily_df_summer_2017[, c( "mean_AirTemperature_C",  "mean_StreamTemp" )], # selecting 2 variables
   start = 1,
   end =  dim(daily_df_summer_2017)[1],
   frequency = 1)
ts
```

```{r}
ts_plot( ts,
        title = "USGS 13251000 PAYETTE RIVER NR PAYETTE ID ",
        Ytitle =    "mean StreamTemp",
        Xtitle = " ", )
```

```{r}
par(mfrow = c(1, 2))
# acf R time series
# c("tavg_wat_C","tavg_air_C")
ts[, c( "mean_AirTemperature_C" )] %>% 
  acf(lag.max = 30, 
      main = "Autocorrelation Plot - max_AirTemperature_C")
# pacf R time series
ts[, c(  "mean_StreamTemp")] %>%
  pacf(lag.max = 30,
       main = "Partial Autocorrelation Plot - max_StreamTemp")
```

```{r}
# ccf time series
par(mfrow=c(1,1))
ccf( ts[, c( "mean_StreamTemp")],  ts[, c( "mean_AirTemperature_C")], 
    lag.max = 11,
    main = "Cros-Correlation Plot",
    ylab = "CCF")
# ccf time series
par(mfrow=c(1,1))
ccf( ts[, c( "mean_AirTemperature_C")],  ts[, c( "mean_StreamTemp")], 
    lag.max = 11,
    main = "Cros-Correlation Plot",
    ylab = "CCF")

```


```{r}
M <-cor( daily_df_summer_2017[,c("max_AirTemperature_C","mean_StreamTemp","log_median_Q", "doy")])
corrplot(M, type="upper", order="hclust",
         col=brewer.pal(n=8, name="RdYlBu"))
```

```{r}
daily_df_summer<-daily_df_summer[daily_df_summer$yr %in% c(2016,2017,2018),]
# set seed for generating random data.
set.seed(0)          
# createDataPartition() function from the caret package to split the original dataset into a training and testing set and split data into training (80%) and testing set (20%)
variables<-c("mean_StreamTemp","max_AirTemperature_C", "log_median_Q", "doy")
parts = createDataPartition(  daily_df_summer$mean_StreamTemp , p = .8, list = F)
train = daily_df_summer[parts, variables ]
test =  daily_df_summer[-parts, variables  ]
# feature and target array
test_x = test[, -1] 
test_y = test[, 1] 
```


```{r}
model_gbm = gbm(train$mean_StreamTemp      ~.,
                data = train,
                distribution = "gaussian",
                cv.folds = 10,
                shrinkage = .01,
                n.minobsinnode = 10,
                n.trees = 800)
 
# model performance
perf_gbm1 = gbm.perf( model_gbm, method = "cv")
print(model_gbm)
summary(model_gbm)
rinf<-summary(model_gbm)
barplot( rinf$rel.inf , horiz = TRUE, las = 1)
ggplot(rinf, aes(rel.inf)) + geom_bar()
```

```{r}
rinf$var<- factor(rinf$var, levels=c(  "max_AirTemperature_C" ,"log_median_Q"
, "doy"  ))
ggplot( rinf, aes( var , rel.inf ))+  geom_col()+ 
  coord_flip()
ggplot( rinf )+  geom_bar(  aes( x=var, y= rel.inf),  stat = "summary")+ scale_x_discrete(labels=  c( "max_AirTemperature_C" ,"log_median_Q"
, "doy") )+ylab("Relative importance (%)") +xlab(" ")  + theme(text=element_text(size=11))
```

```{r}
#test_y <-test_y$max_StreamTemp
pred_y = predict.gbm(model_gbm, test_x)
residuals =  test_y   - pred_y
summary(test_y )
xlim=c(0,30)
RMSE = sqrt(mean(residuals^2))
cat('The root mean square error of the test data is ', round(RMSE,3),'\n')
y_test_mean = mean( test_y  )
# Calculate total sum of squares
tss =  sum(( test_y   - y_test_mean)^2 )
# Calculate residual sum of squares
rss =  sum(residuals^2)
# Calculate R-squared
rsq  =  1 - (rss/tss)
cat('The R-square of the test data is ', round(rsq,3), '\n')
# visualize the model, actual and predicted data
x_ax = 1:length(pred_y)
plot(x_ax, test_y  , col="blue", pch=20, cex=.9)
lines(x_ax, pred_y, col="red", pch=20, cex=.9) 
plot(  test_y , pred_y,xlim= xlim ,ylim= xlim, xlab="Observed stream temperature (degC)", ylab="Predicted stream temperature (degC)", main="GBM")
par(new=T)
x=seq(1,30)
plot(x,x,type="l",xlim= xlim ,ylim= xlim,xlab="",ylab="")
```

```{r}
model_gbm %>%
  partial(pred.var =  "max_AirTemperature_C"   , n.trees = model_gbm$n.trees, grid.resolution = 100) %>%
  autoplot(rug = TRUE, train = train)+theme(axis.text=element_text(size=21),
        axis.title=element_text(size=24))
#,"min_Discharge"
model_gbm %>%
  partial(pred.var =  "log_median_Q"
             #,"min_Discharge"
               , n.trees = model_gbm$n.trees, grid.resolution = 100) %>%
  autoplot(rug = TRUE, train = train)+theme(axis.text=element_text(size=21),
        axis.title=element_text(size=24))

model_gbm %>%
  partial(pred.var =  "doy"
             #,"min_Discharge"
               , n.trees = model_gbm$n.trees, grid.resolution = 100) %>%
  autoplot(rug = TRUE, train = train)+theme(axis.text=element_text(size=21),
        axis.title=element_text(size=24))

```

Model 1
prism
max stream T
only include 2016 2017 2018
max air T
not include DOY
include air T the day before
single point air T
air T * Q

Model 2
met
mean stream T
include all year
mean air T
include DOY
not include air T the day before
updtream air T









